# AI Chatbot Using Your Data in .NET

A high-performance, AOT-compiled AI chatbot application built with .NET 10 that uses Retrieval-Augmented Generation (RAG) to answer questions about landmarks using Wikipedia data. The application features vector search with **SQLite-vec** (default) or **Pinecone**, OpenAI embeddings, and an embedded web interface for easy deployment.

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Data Flow Diagrams](#data-flow-diagrams)
- [Technical Stack](#technical-stack)
- [Getting Started](#getting-started)
- [Development](#development)
- [Deployment](#deployment)
- [API Documentation](#api-documentation)
- [Configuration](#configuration)

## üéØ Overview

This project demonstrates how to build an intelligent chatbot that can:
- Answer questions about famous landmarks using RAG (Retrieval-Augmented Generation)
- Perform semantic vector search across chunked Wikipedia articles
- Engage in natural conversations with function calling capabilities
- Self-host with a single native executable (AOT compilation)

### Key Concepts

**RAG (Retrieval-Augmented Generation)**: Instead of relying solely on the LLM's training data, the system retrieves relevant context from a knowledge base and includes it in the prompt, leading to more accurate and up-to-date responses.

**Vector Search**: Documents are converted to embeddings (numerical representations) and stored in a vector database. When a user asks a question, it's converted to an embedding and similar documents are retrieved.

**AOT Compilation**: Ahead-of-Time compilation produces a native executable with faster startup times and lower memory usage compared to JIT compilation.

## ‚ú® Features

- **üîç Vector Search**: Semantic search using OpenAI embeddings with SQLite-vec (default) or Pinecone
- **üí¨ Interactive Chat**: Full conversation support with context retention
- **‚ùì RAG Q&A**: Question answering with retrieved context from Wikipedia
- **üîß Index Manager**: Web-based interface to build and manage the vector index
- **üöÄ AOT Compiled**: Native executable for fast startup and low memory footprint
- **üåê Embedded Frontend**: No separate web server needed - everything in one file
- **‚öôÔ∏è Configurable**: Switch between SQLite-vec and Pinecone via configuration
- **üîê Secure**: API keys stored in environment variables, never committed to source

## üèóÔ∏è Architecture

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      User's Browser                          ‚îÇ
‚îÇ                   (React SPA - Embedded)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ HTTP/JSON
                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              ASP.NET Core Web API                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Frontend ‚îÇ  ‚îÇ   API    ‚îÇ  ‚îÇ   Index     ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ Serving  ‚îÇ  ‚îÇ Endpoints‚îÇ  ‚îÇ  Management ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ        ‚îÇ        ‚îÇ          ‚îÇ             ‚îÇ
    ‚îÇ        ‚îÇ        ‚îÇ          ‚îÇ             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SQLite ‚îÇ ‚îÇ   OpenAI   ‚îÇ  ‚îÇ Pinecone ‚îÇ  ‚îÇ  Wikipedia   ‚îÇ
‚îÇ (Local)‚îÇ ‚îÇ(Embeddings ‚îÇ  ‚îÇ (Vector  ‚îÇ  ‚îÇ     API      ‚îÇ
‚îÇContent ‚îÇ ‚îÇ    & Chat) ‚îÇ  ‚îÇ  Search) ‚îÇ  ‚îÇ (Data Source)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Application Layers

1. **Presentation Layer**: Embedded React frontend served at `/ui`
2. **API Layer**: RESTful endpoints for search, chat, and index management
3. **Service Layer**: Business logic for RAG, vector search, and Wikipedia integration
4. **Data Layer**: Pinecone (vectors) + SQLite (document content)

## üìä Data Flow Diagrams

### 1. Index Building Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Clicks "Create Index"
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ POST /api/index/build
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ IndexBuilder     ‚îÇ
‚îÇ Service          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ For each landmark:
     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ                                 ‚îÇ
     ‚ñº                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Wikipedia API  ‚îÇ            ‚îÇ ArticleSplitter ‚îÇ
‚îÇ Fetch article  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Chunk into      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ sections        ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚îÇ Chunks
                                   ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ OpenAI          ‚îÇ
                              ‚îÇ Generate        ‚îÇ
                              ‚îÇ Embeddings      ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                              ‚îÇ
                    ‚ñº                              ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Pinecone    ‚îÇ              ‚îÇ   SQLite     ‚îÇ
            ‚îÇ Store vectors‚îÇ              ‚îÇ Store chunks ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Vector Search Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Enters search query
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ GET /api/search?query=...
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VectorSearchService‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 1. Convert query to embedding
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   OpenAI     ‚îÇ
‚îÇ  Embedding   ‚îÇ
‚îÇ  Generator   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 2. Search similar vectors
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Pinecone    ‚îÇ
‚îÇ  Query API   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 3. Retrieve IDs
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DocumentChunk  ‚îÇ
‚îÇ     Store      ‚îÇ
‚îÇ   (SQLite)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 4. Return matched chunks
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Sees search results
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3. RAG Question Answering Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Asks question
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ GET /api/ask?question=...
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RagQuestionService  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 1. Search relevant context
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VectorSearchService ‚îÇ
‚îÇ (Top 5 chunks)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 2. Build RAG prompt
     ‚îÇ    "Based on this context: [chunks]
     ‚îÇ     Answer: [question]"
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   OpenAI     ‚îÇ
‚îÇ Chat API     ‚îÇ
‚îÇ (GPT Model)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ 3. Return answer
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Receives answer
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4. Chat with Function Calling Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Sends message
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ POST /api/chat
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Chat Endpoint      ‚îÇ
‚îÇ + System Prompt    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ With function: database_search_service
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   OpenAI     ‚îÇ
‚îÇ Chat API     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îú‚îÄ If model decides to call function ‚îÄ‚îê
     ‚îÇ                                      ‚îÇ
     ‚îÇ                                      ‚ñº
     ‚îÇ                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ                              ‚îÇ VectorSearchSvc  ‚îÇ
     ‚îÇ                              ‚îÇ FindInDatabase() ‚îÇ
     ‚îÇ                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                                   ‚îÇ
     ‚îÇ                              Returns results
     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îÇ Model generates final response
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User   ‚îÇ Receives answer
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è Technical Stack

### Backend
- **.NET 10** - Latest .NET framework with AOT support
- **ASP.NET Core** - Web API framework
- **Pinecone** - Vector database for semantic search
- **OpenAI API** - Embeddings (text-embedding-3-small) and Chat (GPT-4)
- **SQLite** - Local storage for document chunks
- **Microsoft.Extensions.AI** - Unified AI client abstraction

### Frontend
- **React 18** (via CDN) - UI framework
- **Tailwind CSS** (via CDN) - Styling
- **Babel Standalone** - JSX transformation in browser

### Infrastructure
- **DotNetEnv** - .env file configuration
- **Source Generators** - AOT-compatible JSON serialization

## üöÄ Getting Started

### Prerequisites

- [.NET 10 SDK](https://dotnet.microsoft.com/download/dotnet/10.0)
- OpenAI API Key ([Get one here](https://platform.openai.com/api-keys))
- **For SQLite-vec (default):** `vec0.dll` extension (see setup below)
- **For Pinecone:** API Key ([Get one here](https://www.pinecone.io/)) and Index named `landmark-chunks`

### SQLite-vec Extension Setup (Default Provider)

The application uses SQLite-vec by default for local vector storage. You need the native extension:

**Option 1: Automated (Windows)**
```powai-chatbot-using-your-data-in-dotnet
   ```

2. **Setup SQLite-vec extension** (if using default provider)
   ```powershell
   .\download-sqlite-vec.ps1
   ```
   Or download manually following the steps above.

3. **Configure environment variables**
   
   Edit the `.env` file:
   ```bash
   OPENAI_API_KEY=your-openai-key-here
   # For Pinecone (optional):
   # PINECONE_API_KEY=your-pinecone-key-here
   PORT=5108
   ```

4. **Run the application**
   ```bash
   dotnet run
   ```

5. **Open your browser**
   
   The application will automatically open at `http://localhost:5108/ui`

6. **Build the index**
   
   Navigate to "Index Manager" and click "Build Index" to populate the vector database with Wikipedia articles about landmarks.

### Switching Vector Store Providers

Edit `appsettings.json`:

```json
{
  "VectorStore": {
    "Provider": "SqliteVec"  // or "Pinecone"
  }
}
```

- **SqliteVec** (default): Local storage, no external dependencies, faster queries
- **Pinecone**: Cloud-based, scales to millions of vectors, requires API key

See [VECTOR_STORE_COMPARISON.md](VECTOR_STORE_COMPARISON.md) for detailed comparison
2. **Configure environment variables**
   
   Edit the `.env` file:
   ```bash
   OPENAI_API_KEY=your-openai-key-here
   PINECONE_API_KEY=your-pinecone-key-here
   PORT=5108
   ```

3. **Run the application**
   ```bash
   dotnet run
   ```

4. **Open your browser**
   
   The application will automatically open at `http://localhost:5108/ui`

5. **Build the index**
   
   Navigate to "Index Manager" and click "Create Index" to populate the vector database with Wikipedia articles about landmarks.

## üíª Development

### Project Structure

```
backend/
‚îú‚îÄ‚îÄ Program.cs                 # Application entry point
‚îú‚îÄ‚îÄ Startup.cs                 # Service configuration
‚îú‚îÄ‚îÄ EmbeddedFrontend.cs        # Embedded HTML pages
‚îú‚îÄ‚îÄ AppJsonSerializerContext.cs # JSON source generation
‚îú‚îÄ‚îÄ FunctionRegistry.cs        # AI function definitions
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îú‚îÄ‚îÄ Document.cs
‚îÇ   ‚îú‚îÄ‚îÄ DocumentChunk.cs
‚îÇ   ‚îî‚îÄ‚îÄ IndexResponses.cs
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îú‚îÄ‚îÄ ArticleSplitter.cs     # Text chunking
‚îÇ   ‚îú‚îÄ‚îÄ DocumentStore.cs       # SQLite storage
‚îÇ   ‚îú‚îÄ‚îÄ DocumentChunkStore.cs
‚îÇ   ‚îú‚îÄ‚îÄ IndexBuilder.cs        # Vector index creation
‚îÇ   ‚îú‚îÄ‚îÄ VectorSearchService.cs # Search functionality
‚îÇ   ‚îú‚îÄ‚îÄ RagQuestionService.cs  # RAG implementation
‚îÇ   ‚îú‚îÄ‚îÄ WikipediaClient.cs     # Wikipedia API client
‚îÇ   ‚îú‚îÄ‚îÄ WikipediaJsonContext.cs # JSON context for Wikipedia
‚îÇ   ‚îî‚îÄ‚îÄ PromptService.cs       # Prompt templates
‚îú‚îÄ‚îÄ Prompts/
‚îÇ   ‚îú‚îÄ‚îÄ ChatSystemPrompt.txt
‚îÇ   ‚îú‚îÄ‚îÄ HydePrompt.txt
‚îÇ   ‚îî‚îÄ‚îÄ RagSystemPrompt.txt
‚îî‚îÄ‚îÄ .env                       # Environment configuration
```

### Running in Development Mode

#### Visual Studio Code
1. Press **F5** to start debugging
2. Set breakpoints in any .cs file
3. Use Debug Console for REPL

#### Command Line
```bash
# Development mode (with hot reload)
dotnet watch run

# Standard run
dotnet run

# With specific port
PORT=8080 dotnet run
```

### Adding New Features

#### Adding a New API Endpoint

1. **Add endpoint in Program.cs**:
   ```csharp
   app.MapGet("/api/myendpoint", async () =>
   {
       return Results.Ok(new MyResponse("data"));
   });
   ```

2. **Create response type in Models/**:
   ```csharp
   public record MyResponse(string Data);
   ```

3. **Register in AppJsonSerializerContext.cs**:
   ```csharp
   [JsonSerializable(typeof(MyResponse))]
   ```

#### Adding a New Frontend Page

1. **Add HTML constant in EmbeddedFrontend.cs**:
   ```csharp
   public const string MyPageHtml = """
   <!DOCTYPE html>
   ...
   """;
   ```

2. **Register route in Program.cs**:
   ```csharp
   app.MapGet("/ui/mypage", () => 
       Results.Content(EmbeddedFrontend.MyPageHtml, "text/html"));
   ```

### Testing

```bash
# Run all tests
dotnet test

# With code coverage
dotnet test /p:CollectCoverage=true
```

### Code Quality

```bash
# Format code
dotnet format

# Analyze code
dotnet build /p:EnforceCodeStyleInBuild=true
```

## üì¶ Deployment

### Building for Production

#### Standard Build
```bash
dotnet build -c Release
```

#### AOT Native Build
```bash
dotnet publish -c Release
```

Output location: `bin/Release/net10.0/win-x64/publish/ChatBot.exe`

### AOT Compilation Benefits

- **Faster Startup**: ~10x faster than JIT
- **Lower Memory**: Reduced baseline memory usage
- **Single Executable**: Everything bundled (except .env)
- **Smaller Size**: Trimmed unused code

### Deployment Options

#### 1. Self-Contained Executable

The published AOT executable is fully self-contained:

```bash
# Copy these files to your server:
ChatBot.exe              # Main executable
.env                     # Configuration (create on server)
contentstore.db          # SQLite database (auto-created)
```

#### 2. Windows Service

```bash
# Install as Windows Service
sc create ChatBotService binPath="C:\path\to\ChatBot.exe"
sc start ChatBotService
```

#### 3. Docker Container

Create `Dockerfile`:
```dockerfile
FROM mcr.microsoft.com/dotnet/aspnet:10.0-alpine
WORKDIR /app
COPY bin/Release/net10.0/linux-x64/publish/ .
EXPOSE 5108
ENTRYPOINT ["./ChatBot"]
```

Build and run:
```bash
docker build -t chatbot .
docker run -p 5108:5108 -e OPENAI_API_KEY=xxx -e PINECONE_API_KEY=xxx chatbot
```

#### 4. Cloud Deployment

**Azure App Service**:
```bash
az webapp up --name my-chatbot --runtime "DOTNET:10.0"
```

**AWS Elastic Beanstalk**:
```bash
eb init -p "64bit Amazon Linux 2 v2.0.0 running .NET 10"
eb create chatbot-env
```

### Environment Variables in Production

**Never commit** `.env` to source control. Set environment variables directly:

**Windows**:
```powershell
$env:OPENAI_API_KEY = "your-key"
$env:PINECONE_API_KEY = "your-key"
```

**Linux/Mac**:
```bash
export OPENAI_API_KEY="your-key"
export PINECONE_API_KEY="your-key"
```

**Docker**:
```bash
docker run -e OPENAI_API_KEY=xxx -e PINECONE_API_KEY=xxx chatbot
```

## üì° API Documentation

### Frontend Routes

| Route                     | Description                   |
| ------------------------- | ----------------------------- |
| `GET /ui`                 | Main index page with links    |
| `GET /ui/indexer`         | Index management interface    |
| `GET /ui/chat`            | Chat interface                |
| `GET /ui/question`        | Q&A interface                 |
| `GET /ui/searchchunks`    | Search chunks of articles     |
| `GET /ui/searchlandmarks` | Search landmark introductions |

### API Endpoints

#### Index Management

**Get Index Statistics**
```http
GET /api/index/list
```
Response:
```json
{
  "count": 325,
  "hasRecords": true
}
```

**Build Index**
```http
POST /api/index/build
```
Response:
```json
{
  "message": "Index built successfully",
  "recordCount": 52
}
```

#### Search

**Vector Search**
```http
GET /api/search?query=ancient+stone+structure
```
Response:
```json
[
  {
    "id": "stonehenge_intro_0",
    "title": "Stonehenge",
    "section": "Introduction",
    "chunkIndex": 0,
    "content": "Stonehenge is a prehistoric...",
    "sourcePageUrl": "https://en.wikipedia.org/wiki/Stonehenge"
  }
]
```

#### Question Answering

**Ask Question (RAG)**
```http
GET /api/ask?question=When+was+Stonehenge+built
```
Response:
```json
"Stonehenge was built in several stages between approximately 3000 BC and 2000 BC, with the most famous stone circle being erected around 2500 BC."
```

#### Chat

**Chat with AI**
```http
POST /api/chat
Content-Type: application/json

[
  {
    "role": "user",
    "contents": [
      {
        "$type": "text",
        "text": "Tell me about the Eiffel Tower"
      }
    ]
  }
]
```

## ‚öôÔ∏è Configuration

### Environment Variables

| Variable           | Required | Default | Description                            |
| ------------------ | -------- | ------- | -------------------------------------- |
| `OPENAI_API_KEY`   | Yes      | -       | OpenAI API key for embeddings and chat |
| `PINECONE_API_KEY` | Yes      | -       | Pinecone API key for vector database   |
| `PORT`             | No       | 5108    | HTTP port to listen on                 |

### Pinecone Index Setup

1. Create a new index in Pinecone console
2. Name: `landmark-chunks`
3. Dimensions: `512`
4. Metric: `cosine`
5. Pod Type: `s1.x1` or higher

### Customizing Data Sources

Edit `SourceData.cs` to change the landmarks:

```csharp
public static readonly string[] LandmarkNames =
[
    "Your Custom Landmark 1",
    "Your Custom Landmark 2",
    // ...
];
```

## üîß Troubleshooting

### Common Issues

**Port already in use**
```bash
# Change port in .env
PORT=8080
```

**API key errors**
```bash
# Verify environment variables are set
echo $env:OPENAI_API_KEY
```

**AOT compilation warnings**
- WikipediaClient warnings are expected (only used during indexing)
- All runtime code is fully AOT-compatible

**Index not building**
- Check Pinecone index exists and is named `landmark-chunks`
- Verify API keys have correct permissions
- Check network connectivity

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üôè Acknowledgments

- Built as part of Dometrain's "AI Chatbot Using Your Data in .NET" course
- Uses OpenAI's GPT models and embedding API
- Vector search powered by Pinecone
- Wikipedia as the knowledge source

## üìö Further Reading

- [RAG (Retrieval-Augmented Generation) Overview](https://arxiv.org/abs/2005.11401)
- [.NET Native AOT Deployment](https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/)
- [Microsoft.Extensions.AI Documentation](https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-ai-preview/)
- [Pinecone Vector Database](https://docs.pinecone.io/)
